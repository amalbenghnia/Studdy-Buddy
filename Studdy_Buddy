## importer les bibliothèques :

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping ,ModelCheckpoint
from tensorflow.keras.models import load_model
from sklearn.metrics import classification_report, confusion_matrix
import cv2
import os 

MG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 30

## télecharger dataset :

dataset_path='/content/drive/MyDrive/archive (1)/dataset_new'
train_dir = os.path.join (dataset_path ,'train')
test_dir = os.path.join (dataset_path ,'test')

# Prétraitement avec Data Augmentation
train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=15,
                                   zoom_range=0.2,
                                   shear_range=0.1,
                                   horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)
# verification des classes :

print("Classes détectées :", train_generator.class_indices)
class_names = list(train_generator.class_indices.keys())

# modéle avec MobileNetV2 :

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
base_model.trainable = True
for layer in base_model.layers[:-80]:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(64, activation='relu')(x)
predictions = Dense(len(class_names), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# trainning :

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)
history = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=EPOCHS,
    callbacks=[early_stop,checkpoint]
) 
# Matrice du confusion :

print('Confusion Matrix')
print(confusion_matrix(test_generator.classes, y_pred))

print('Classification Report')
target_names = list(test_generator.class_indices.keys())
print(classification_report(test_generator.classes, y_pred, target_names=target_names))

# testing:
model = load_model("/content/drive/MyDrive/model/drowsiness_model_v2.h5")
img_path = "/content/drive/MyDrive/archive (1)/dataset_new/test/Open/_120.jpg"
img = cv2.imread(img_path)

# Vérifier que l'image a bien été lue :

if img is None:
    print("Erreur : image non trouvée. Vérifie le chemin.")
else:

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (224, 224))
    img = np.expand_dims(img, axis=0) / 255.0

## Faire une prédiction :

pred = model.predict(img)
predicted_class = np.argmax(pred)
confidence = np.max(pred)
predicted_class = np.argmax(pred)
label = classes[predicted_class]
confidence = np.max(pred)

# Affichage du message selon la classe :

if label == "Closed":
    message = "Eyes Closed -Wake up!"
elif label == "Open":
    message = "Eyes open"
elif label == "no_yawn": # Changed "no-yawn" to "no_yawn" to match the actual label
    message = "No yawn detected "
elif label == "yawn":
    message = "Yawning - Be careful!"
print(f"Message: {message}")
print(f"Classe prédite : {classes[predicted_class]} avec une confiance de {confidence*100:.2f}%")


 

